env_args: {}
ppo_args:
  batch_size: 64
  clip_range: 0.2
  ent_coeff: 0.001
  gamma: 0.99
  learning_rate: 0.0003
  n_epochs: 10
  n_steps: 2048
  policy_kwargs:
    activation_fn: torch.nn.modules.activation.ReLU
    net_arch:
      pi:
      - 256
      - 256
      vf:
      - 256
      - 256
tonic:
  after_training: ''
  agent: PPO(policy=ActorCriticPolicy, env='myoChallengeBimanual-v0')
  before_training: ''
  checkpoint: last
  environment: gym.make('myoChallengeBimanual-v0')
  environment_name: bimanual_test
  header: import stable_baselines3, gym
  name: myoarm+MPL
  parallel: 2
  seed: 0
  test_environment: null
  trainer: PPOTrainer(total_timesteps=100000000)
working_dir: baselines_sb3/bimanual
